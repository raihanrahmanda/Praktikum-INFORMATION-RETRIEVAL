{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print list index 1\n",
      "Kamu\n",
      "\n",
      "menampilkan semua anggota list\n",
      "1\n",
      "2\n",
      "tiga\n",
      "empat\n",
      "5\n",
      "\n",
      "alternatif lain menampilkan semua anggota list\n",
      "1\n",
      "2\n",
      "tiga\n",
      "empat\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(\"print list index 1\")\n",
    "list1 = [\"Wilayah\", \"Kamu\", \"Sudah\", \"Bebas\", \"COVID-19\", \"?\"]\n",
    "print(list1[1])\n",
    "\n",
    "list2 = [1, 2, \"tiga\", \"empat\", 5]\n",
    "#menampilkan semua anggota list\n",
    "print(\"\\nmenampilkan semua anggota list\")\n",
    "for i in range(len(list2)):\n",
    "    print(list2[i])\n",
    "\n",
    "#atau\n",
    "print(\"\\nalternatif lain menampilkan semua anggota list\")\n",
    "for list in list2:\n",
    "    print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary dengan key 1\n",
      "Wilayah\n",
      "\n",
      "menampilkan semua anggota dictionary\n",
      "elemen:  januari\n",
      "key   :  1\n",
      "\n",
      "\n",
      "elemen:  februari\n",
      "key   :  2\n",
      "\n",
      "\n",
      "elemen:  maret\n",
      "key   :  3\n",
      "\n",
      "\n",
      "elemen:  april\n",
      "key   :  4\n",
      "\n",
      "\n",
      "elemen:  mei\n",
      "key   :  5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"dictionary dengan key 1\")\n",
    "dict1 = {1: \"Wilayah\", 2: \"Kamu\", 3: \"Sudah\", 4: \"Bebas\", 5: \"COVID-19\", 6: \"?\"}\n",
    "print(dict1[1])\n",
    "\n",
    "print(\"\\nmenampilkan semua anggota dictionary\")\n",
    "dict2 = {\"januari\": 1, \"februari\": 2, \"maret\": 3, \"april\": 4, \"mei\": 5}\n",
    "for key in dict2:\n",
    "    #print elemen berdasarkan key\n",
    "    print(\"elemen: \", key)\n",
    "    print(\"key   : \", dict2[key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pengembangan': 2, 'sistem': 2, 'informasi': 1, 'penjadwalan': 1, 'model': 1, 'analisis': 2, 'sentimen': 1, 'berita': 1, 'input': 1, 'output': 1}\n"
     ]
    }
   ],
   "source": [
    "doc1 = \"pengembangan sistem informasi penjadwalan\"\n",
    "doc1_term = [\"pengembangan\", \"sistem\", \"informasi\", \"penjadwalan\"]\n",
    "\n",
    "doc2 = \"pengembangan model analisis sentimen berita\"\n",
    "doc2_term = [\"pengembangan\", \"model\", \"analisis\", \"sentimen\", \"berita\"]\n",
    "\n",
    "doc3 = \"pengembangan model analisis sentimen berita\"\n",
    "doc3_term = [\"analisis\", \"sistem\", \"input\", \"output\"]\n",
    "\n",
    "corpus = [doc1, doc2, doc3]\n",
    "corpus_term = [doc1_term, doc2_term, doc3_term]\n",
    "\n",
    "vocabulary = {}\n",
    "for d in corpus_term:\n",
    "    for term in d:\n",
    "        if term not in vocabulary:\n",
    "            vocabulary[term] = 1\n",
    "        else:\n",
    "            vocabulary[term] = vocabulary[term]+1\n",
    "            \n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pengembangan sistem informasi penjadwalan (akan ditokenisasi menjadi):\n",
      "['pengembangan', 'sistem', 'informasi', 'penjadwalan']\n",
      "\n",
      "\n",
      "pengembangan model analisis sentimen berita (akan ditokenisasi menjadi):\n",
      "['pengembangan', 'model', 'analisis', 'sentimen', 'berita']\n",
      "\n",
      "\n",
      "pengembangan model analisis sentimen berita (akan ditokenisasi menjadi):\n",
      "['pengembangan', 'model', 'analisis', 'sentimen', 'berita']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fungsi tokenisasi\n",
    "def tokenisasi(text):\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "doc1 = \"pengembangan sistem informasi penjadwalan\"\n",
    "doc2 = \"pengembangan model analisis sentimen berita\"\n",
    "doc3 = \"pengembangan model analisis sentimen berita\"\n",
    "corpus = [doc1, doc2, doc3]\n",
    "\n",
    "for d in corpus:\n",
    "    print(d, \"(akan ditokenisasi menjadi):\")\n",
    "    token_kata = tokenisasi(d)\n",
    "    print(token_kata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pengembangan', 'sistem', 'informasi', 'penjadwalan']\n",
      "['pengembangan', 'model', 'analisis', 'sentimen', 'berita']\n",
      "['pengembangan', 'model', 'analisis', 'sentimen', 'berita']\n"
     ]
    }
   ],
   "source": [
    "#dengan library spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "import spacy\n",
    "\n",
    "nlp = Indonesian() # use directly\n",
    "nlp = spacy.blank('id') # blank instance'\n",
    "\n",
    "for d in corpus:\n",
    "    spacy_id = nlp(d)\n",
    "    token_kata = [token.text for token in spacy_id]\n",
    "    print(token_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks original: \n",
      "Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\n",
      "\n",
      "Teks uppercase: \n",
      "WILAYAH KAMU SUDAH 'BEBAS' COVID-19? CEK 34 KAB/KOTA ZONA HIJAU TERBARU\n",
      "\n",
      "Teks lowercase: \n",
      "wilayah kamu sudah 'bebas' covid-19? cek 34 kab/kota zona hijau terbaru\n"
     ]
    }
   ],
   "source": [
    "text = \"Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\"\n",
    "text_capital = text.upper()\n",
    "text_lower = text.lower()\n",
    "\n",
    "print(\"Teks original: \")\n",
    "print(text)\n",
    "\n",
    "print(\"\\nTeks uppercase: \")\n",
    "print(text_capital)\n",
    "\n",
    "print(\"\\nTeks lowercase: \")\n",
    "print(text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wilayah', 'kamu', 'bebas', 'covid-19', '?', 'cek', '34', 'kab', '/', 'kota', 'zona', 'hijau', 'terbaru']\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\"yang\", \"dari\", \"sudah\", \"dan\"]\n",
    "text = \"Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\"\n",
    "tokens = [\"wilayah\", \"kamu\", \"sudah\", \"bebas\", \"covid-19\", \"?\", \"cek\", \"34\", \"kab\", \"/\", \"kota\", \"zona\", \"hijau\", \"terbaru\"]\n",
    "\n",
    "tokens_nostopword = [w for w in tokens if not w in stopwords]\n",
    "print(tokens_nostopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wilayah', 'bebas', 'covid-19', '?', 'cek', '34', 'kab', '/', 'kota', 'zona', 'hijau', 'terbaru']\n"
     ]
    }
   ],
   "source": [
    "#dengan library spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "import spacy\n",
    "\n",
    "nlp = Indonesian() # use directly\n",
    "nlp = spacy.blank('id') # blank instance'\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "tokens_nostopword = [w for w in tokens if not w in stopwords]\n",
    "print(tokens_nostopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saya', 'sedang', 'di', 'jalan', 'nih']\n"
     ]
    }
   ],
   "source": [
    "normal_list = {\"gue\": \"saya\", \"gua\": \"saya\", \"aku\": \"saya\", \"aq\": \"saya\", \"lagi\": \"sedang\"}\n",
    "text = \"aq lagi di jalan nih\"\n",
    "text_normal = []\n",
    "\n",
    "for t in text.split(\" \"):\n",
    "    text_normal.append(normal_list[t] if t in normal_list else t)\n",
    "print(text_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wilayah kamu sudah bebas covid-19 cek 34 kab kota zona hijau baru\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# stemming process\n",
    "text = \"Wilayah Kamu Sudah 'Bebas' COVID-19? Cek 34 Kab/Kota Zona Hijau Terbaru\"\n",
    "output = stemmer.stem(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mobilitas warga bakal diperketat melalui penerapan\\nPPKM level 3 se-Indonesia di masa libur Natal dan\\ntahun baru (Nataru). Rencana kebijakan itu dikritik\\noleh Epidemiolog dari Griffith University Dicky\\nBudiman.', 'Dicky menyebut pembatasan mobilitas memang akan\\nmemiliki dampak dalam mencegah penularan COVID-19.\\nTapi, kata dia, dampaknya signifikan atau tidak akan\\nbergantung pada konsistensi yang mendasar yakni\\ntesting, tracing, treatment (3T) hingga vaksinasi \\nCOVID-19.']\n"
     ]
    }
   ],
   "source": [
    "doctask = '''Mobilitas warga bakal diperketat melalui penerapan\n",
    "PPKM level 3 se-Indonesia di masa libur Natal dan\n",
    "tahun baru (Nataru). Rencana kebijakan itu dikritik\n",
    "oleh Epidemiolog dari Griffith University Dicky\n",
    "Budiman.\n",
    "\n",
    "Dicky menyebut pembatasan mobilitas memang akan\n",
    "memiliki dampak dalam mencegah penularan COVID-19.\n",
    "Tapi, kata dia, dampaknya signifikan atau tidak akan\n",
    "bergantung pada konsistensi yang mendasar yakni\n",
    "testing, tracing, treatment (3T) hingga vaksinasi \n",
    "COVID-19.'''\n",
    "\n",
    "#fungsi untuk memisahkan paragraf dalam suatu dokumen\n",
    "def paragraph_parsing(text):\n",
    "    paragraphs = text.split(\"\\n\\n\")\n",
    "    return paragraphs\n",
    "\n",
    "list_paragraph = paragraph_parsing(doctask)\n",
    "print(list_paragraph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
