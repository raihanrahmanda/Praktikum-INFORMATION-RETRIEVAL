{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5508517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 term frequencies:\n",
      "WILAYAH: 2\n",
      "KAMU: 2\n",
      "SUDAH: 2\n",
      "BEBAS: 2\n",
      "COVID: 3\n",
      "-: 16\n",
      "19: 3\n",
      "CEK: 2\n",
      "34: 2\n",
      "KAB: 2\n",
      "KOTA: 2\n",
      "ZONA: 2\n",
      "HIJAU: 2\n",
      "BARU: 2\n",
      "JAKARTA: 1\n",
      "PERINTAH: 1\n",
      "RENCANA: 1\n",
      "TERAP: 2\n",
      "LAKU: 1\n",
      "BATAS: 1\n",
      "GIAT: 1\n",
      "MASYARAKAT: 1\n",
      "PPKM: 3\n",
      "LEVEL: 3\n",
      "3: 5\n",
      "HITUNG: 1\n",
      "24: 1\n",
      "DESEMBER: 1\n",
      "2021: 2\n",
      "2: 7\n",
      "JANUARI: 1\n",
      "NAMUN: 1\n",
      "MENTERI: 1\n",
      "SEHAT: 2\n",
      "RI: 6\n",
      "BIJAK: 1\n",
      "TAHAP: 1\n",
      "KAJI: 1\n",
      "TURUT: 1\n",
      "DIREKTUR: 1\n",
      "CEGAH: 1\n",
      "KENDALI: 1\n",
      "SAKIT: 1\n",
      "TULAR: 1\n",
      "LANGSUNG: 1\n",
      "P2PML: 1\n",
      "KEMENKES: 1\n",
      "DR: 1\n",
      "SITI: 1\n",
      "NADIA: 1\n",
      "TARMIZI: 1\n",
      "SIGNIFIKAN: 1\n",
      "HAL: 1\n",
      "PICU: 1\n",
      "TINGKAT: 1\n",
      "MOBILITAS: 1\n",
      "LONGGAR: 1\n",
      "PROTOKOL: 1\n",
      "HTTPS: 1\n",
      "HEALTH: 2\n",
      "DETIK: 2\n",
      "COM: 1\n",
      "BERITA-DETIKHEALTH: 1\n",
      "D-5816690: 1\n",
      "WILAYAH-KAMU-SUDAH-BEBAS-COVID-19-CEK-34-KABKOTA-ZONA-HIJAU-TERBARU: 1\n",
      "VAKSIN: 0\n",
      "BAKAL: 0\n",
      "RUTIN: 0\n",
      "TIAP: 0\n",
      "TAHUN: 0\n",
      "GANTUNG: 0\n",
      "INI: 0\n",
      "JELAS: 0\n",
      "BERI: 1\n",
      "BOOSTER: 0\n",
      "DOSIS: 0\n",
      "TIGA: 0\n",
      "INDONESIA: 0\n",
      "2022: 0\n",
      "LANTAS: 0\n",
      "ADA: 0\n",
      "VAKSINASI: 0\n",
      "INFLUENZA: 0\n",
      "KETUA: 0\n",
      "SATGAS: 0\n",
      "IKAT: 0\n",
      "DOKTER: 0\n",
      "IDI: 0\n",
      "PROF: 0\n",
      "ZUBAIRI: 0\n",
      "DJOERBAN: 0\n",
      "PASTI: 0\n",
      "KAIT: 0\n",
      "D-5816582: 0\n",
      "VAKSIN-COVID-19-BAKAL-RUTIN-SETIAP-TAHUN-TERGANTUNG-INI-PENJELASANNYA: 0\n",
      "MULAI: 0\n",
      "SUNTIK: 0\n",
      "MASIH: 0\n",
      "AMPUH: 0\n",
      "LAWAN: 0\n",
      "VARIAN: 0\n",
      "DELTA: 0\n",
      "CS: 0\n",
      "PAKAR: 0\n",
      "AKU: 1\n",
      "1: 6\n",
      "ALAMI: 0\n",
      "TURUN: 0\n",
      "EFEKTIVITAS: 0\n",
      "CORONA: 0\n",
      "INGAT: 0\n",
      "JENIS: 0\n",
      "IKUT: 0\n",
      "STRAIN: 0\n",
      "VIRUS: 0\n",
      "JAWAB: 0\n",
      "SINGGUNG: 0\n",
      "RISET: 0\n",
      "IA: 2\n",
      "SEBUT: 0\n",
      "DASAR: 0\n",
      "PFIZER: 0\n",
      "MODERNA: 0\n",
      "BUKTI: 0\n",
      "D-5816534: 0\n",
      "RI-MULAI-SUNTIKKAN-BOOSTER-DI-2022-MASIHKAH-AMPUH-LAWAN-VARIAN-DELTA-CS: 0\n",
      "ALERT: 0\n",
      "KASUS: 0\n",
      "DKI: 0\n",
      "DATA: 0\n",
      "BALITBANGKES: 0\n",
      "13: 0\n",
      "NOVEMBER: 0\n",
      "TAMBAH: 0\n",
      "JAWA: 0\n",
      "BARAT: 0\n",
      "165: 0\n",
      "90: 1\n",
      "SULAWESI: 0\n",
      "UTARA: 0\n",
      "86: 0\n",
      "DALAM: 0\n",
      "SEMENTARA: 0\n",
      "ALPHA: 0\n",
      "BETA: 0\n",
      "ASAL: 0\n",
      "TOTAL: 0\n",
      "327: 0\n",
      "D-5812940: 0\n",
      "ALERT-KASUS-VARIAN-DELTA-COVID-19-DI-DKI-MENINGKAT: 0\n",
      "AS: 5\n",
      "DADAK: 0\n",
      "NAIK: 0\n",
      "LAGI: 0\n",
      "USAI: 0\n",
      "SERANG: 0\n",
      "SEMPAT: 0\n",
      "REDA: 0\n",
      "AMERIKA: 0\n",
      "SERIKAT: 0\n",
      "PADAHAL: 0\n",
      "CATAT: 0\n",
      "STABIL: 0\n",
      "PASCA: 0\n",
      "MUSIM: 0\n",
      "PANAS: 0\n",
      "KEPALA: 0\n",
      "NASIHAT: 0\n",
      "MEDIS: 0\n",
      "GEDUNG: 0\n",
      "PUTIH: 0\n",
      "ANTHONY: 0\n",
      "FAUCI: 0\n",
      "SENIN: 0\n",
      "15: 0\n",
      "11: 0\n",
      "TAHU: 0\n",
      "NASIONAL: 0\n",
      "57: 0\n",
      "PERSEN: 0\n",
      "MINGGU: 0\n",
      "PUNCAK: 0\n",
      "GELOMBANG: 0\n",
      "PASIEN: 0\n",
      "AREA: 0\n",
      "TENGAH: 0\n",
      "TIMUR: 0\n",
      "LAUT: 0\n",
      "D-5813949: 0\n",
      "CORONA-DI-AS-MENDADAK-NAIK-LAGI-USAI-SERANGAN-DELTA-SEMPAT-MEREDA: 0\n",
      "Document 2 term frequencies:\n",
      "WILAYAH: 0\n",
      "KAMU: 0\n",
      "SUDAH: 0\n",
      "BEBAS: 0\n",
      "COVID: 7\n",
      "-: 18\n",
      "19: 7\n",
      "CEK: 0\n",
      "34: 0\n",
      "KAB: 0\n",
      "KOTA: 0\n",
      "ZONA: 0\n",
      "HIJAU: 0\n",
      "BARU: 0\n",
      "JAKARTA: 1\n",
      "PERINTAH: 0\n",
      "RENCANA: 1\n",
      "TERAP: 0\n",
      "LAKU: 0\n",
      "BATAS: 0\n",
      "GIAT: 0\n",
      "MASYARAKAT: 0\n",
      "PPKM: 0\n",
      "LEVEL: 0\n",
      "3: 0\n",
      "HITUNG: 0\n",
      "24: 0\n",
      "DESEMBER: 0\n",
      "2021: 0\n",
      "2: 4\n",
      "JANUARI: 1\n",
      "NAMUN: 0\n",
      "MENTERI: 0\n",
      "SEHAT: 0\n",
      "RI: 4\n",
      "BIJAK: 0\n",
      "TAHAP: 0\n",
      "KAJI: 0\n",
      "TURUT: 1\n",
      "DIREKTUR: 0\n",
      "CEGAH: 0\n",
      "KENDALI: 0\n",
      "SAKIT: 0\n",
      "TULAR: 0\n",
      "LANGSUNG: 0\n",
      "P2PML: 0\n",
      "KEMENKES: 0\n",
      "DR: 0\n",
      "SITI: 0\n",
      "NADIA: 0\n",
      "TARMIZI: 0\n",
      "SIGNIFIKAN: 0\n",
      "HAL: 0\n",
      "PICU: 0\n",
      "TINGKAT: 0\n",
      "MOBILITAS: 0\n",
      "LONGGAR: 0\n",
      "PROTOKOL: 0\n",
      "HTTPS: 1\n",
      "HEALTH: 2\n",
      "DETIK: 2\n",
      "COM: 1\n",
      "BERITA-DETIKHEALTH: 1\n",
      "D-5816690: 0\n",
      "WILAYAH-KAMU-SUDAH-BEBAS-COVID-19-CEK-34-KABKOTA-ZONA-HIJAU-TERBARU: 0\n",
      "VAKSIN: 7\n",
      "BAKAL: 2\n",
      "RUTIN: 2\n",
      "TIAP: 2\n",
      "TAHUN: 2\n",
      "GANTUNG: 2\n",
      "INI: 2\n",
      "JELAS: 2\n",
      "BERI: 2\n",
      "BOOSTER: 2\n",
      "DOSIS: 1\n",
      "TIGA: 1\n",
      "INDONESIA: 2\n",
      "2022: 1\n",
      "LANTAS: 1\n",
      "ADA: 1\n",
      "VAKSINASI: 3\n",
      "INFLUENZA: 1\n",
      "KETUA: 1\n",
      "SATGAS: 1\n",
      "IKAT: 1\n",
      "DOKTER: 1\n",
      "IDI: 1\n",
      "PROF: 1\n",
      "ZUBAIRI: 1\n",
      "DJOERBAN: 1\n",
      "PASTI: 1\n",
      "KAIT: 1\n",
      "D-5816582: 1\n",
      "VAKSIN-COVID-19-BAKAL-RUTIN-SETIAP-TAHUN-TERGANTUNG-INI-PENJELASANNYA: 1\n",
      "MULAI: 0\n",
      "SUNTIK: 0\n",
      "MASIH: 0\n",
      "AMPUH: 0\n",
      "LAWAN: 0\n",
      "VARIAN: 0\n",
      "DELTA: 0\n",
      "CS: 0\n",
      "PAKAR: 0\n",
      "AKU: 0\n",
      "1: 8\n",
      "ALAMI: 0\n",
      "TURUN: 0\n",
      "EFEKTIVITAS: 0\n",
      "CORONA: 0\n",
      "INGAT: 0\n",
      "JENIS: 0\n",
      "IKUT: 0\n",
      "STRAIN: 0\n",
      "VIRUS: 0\n",
      "JAWAB: 0\n",
      "SINGGUNG: 0\n",
      "RISET: 0\n",
      "IA: 4\n",
      "SEBUT: 0\n",
      "DASAR: 0\n",
      "PFIZER: 0\n",
      "MODERNA: 0\n",
      "BUKTI: 0\n",
      "D-5816534: 0\n",
      "RI-MULAI-SUNTIKKAN-BOOSTER-DI-2022-MASIHKAH-AMPUH-LAWAN-VARIAN-DELTA-CS: 0\n",
      "ALERT: 0\n",
      "KASUS: 0\n",
      "DKI: 0\n",
      "DATA: 0\n",
      "BALITBANGKES: 0\n",
      "13: 0\n",
      "NOVEMBER: 0\n",
      "TAMBAH: 0\n",
      "JAWA: 0\n",
      "BARAT: 0\n",
      "165: 1\n",
      "90: 0\n",
      "SULAWESI: 0\n",
      "UTARA: 0\n",
      "86: 0\n",
      "DALAM: 0\n",
      "SEMENTARA: 0\n",
      "ALPHA: 0\n",
      "BETA: 0\n",
      "ASAL: 0\n",
      "TOTAL: 0\n",
      "327: 0\n",
      "D-5812940: 0\n",
      "ALERT-KASUS-VARIAN-DELTA-COVID-19-DI-DKI-MENINGKAT: 0\n",
      "AS: 8\n",
      "DADAK: 0\n",
      "NAIK: 0\n",
      "LAGI: 0\n",
      "USAI: 0\n",
      "SERANG: 0\n",
      "SEMPAT: 0\n",
      "REDA: 0\n",
      "AMERIKA: 0\n",
      "SERIKAT: 0\n",
      "PADAHAL: 0\n",
      "CATAT: 0\n",
      "STABIL: 0\n",
      "PASCA: 0\n",
      "MUSIM: 0\n",
      "PANAS: 0\n",
      "KEPALA: 0\n",
      "NASIHAT: 0\n",
      "MEDIS: 0\n",
      "GEDUNG: 0\n",
      "PUTIH: 0\n",
      "ANTHONY: 0\n",
      "FAUCI: 0\n",
      "SENIN: 0\n",
      "15: 0\n",
      "11: 0\n",
      "TAHU: 2\n",
      "NASIONAL: 0\n",
      "57: 0\n",
      "PERSEN: 0\n",
      "MINGGU: 0\n",
      "PUNCAK: 0\n",
      "GELOMBANG: 0\n",
      "PASIEN: 0\n",
      "AREA: 0\n",
      "TENGAH: 0\n",
      "TIMUR: 0\n",
      "LAUT: 0\n",
      "D-5813949: 0\n",
      "CORONA-DI-AS-MENDADAK-NAIK-LAGI-USAI-SERANGAN-DELTA-SEMPAT-MEREDA: 0\n",
      "Document 3 term frequencies:\n",
      "WILAYAH: 0\n",
      "KAMU: 0\n",
      "SUDAH: 0\n",
      "BEBAS: 0\n",
      "COVID: 4\n",
      "-: 20\n",
      "19: 4\n",
      "CEK: 0\n",
      "34: 1\n",
      "KAB: 0\n",
      "KOTA: 0\n",
      "ZONA: 0\n",
      "HIJAU: 0\n",
      "BARU: 1\n",
      "JAKARTA: 1\n",
      "PERINTAH: 0\n",
      "RENCANA: 0\n",
      "TERAP: 0\n",
      "LAKU: 0\n",
      "BATAS: 0\n",
      "GIAT: 0\n",
      "MASYARAKAT: 0\n",
      "PPKM: 0\n",
      "LEVEL: 0\n",
      "3: 1\n",
      "HITUNG: 0\n",
      "24: 0\n",
      "DESEMBER: 0\n",
      "2021: 0\n",
      "2: 11\n",
      "JANUARI: 0\n",
      "NAMUN: 0\n",
      "MENTERI: 0\n",
      "SEHAT: 0\n",
      "RI: 11\n",
      "BIJAK: 0\n",
      "TAHAP: 0\n",
      "KAJI: 0\n",
      "TURUT: 0\n",
      "DIREKTUR: 0\n",
      "CEGAH: 0\n",
      "KENDALI: 0\n",
      "SAKIT: 0\n",
      "TULAR: 0\n",
      "LANGSUNG: 0\n",
      "P2PML: 0\n",
      "KEMENKES: 0\n",
      "DR: 0\n",
      "SITI: 0\n",
      "NADIA: 0\n",
      "TARMIZI: 0\n",
      "SIGNIFIKAN: 0\n",
      "HAL: 0\n",
      "PICU: 0\n",
      "TINGKAT: 0\n",
      "MOBILITAS: 0\n",
      "LONGGAR: 0\n",
      "PROTOKOL: 0\n",
      "HTTPS: 1\n",
      "HEALTH: 2\n",
      "DETIK: 2\n",
      "COM: 1\n",
      "BERITA-DETIKHEALTH: 1\n",
      "D-5816690: 0\n",
      "WILAYAH-KAMU-SUDAH-BEBAS-COVID-19-CEK-34-KABKOTA-ZONA-HIJAU-TERBARU: 0\n",
      "VAKSIN: 6\n",
      "BAKAL: 0\n",
      "RUTIN: 0\n",
      "TIAP: 0\n",
      "TAHUN: 0\n",
      "GANTUNG: 0\n",
      "INI: 0\n",
      "JELAS: 0\n",
      "BERI: 1\n",
      "BOOSTER: 3\n",
      "DOSIS: 3\n",
      "TIGA: 1\n",
      "INDONESIA: 2\n",
      "2022: 3\n",
      "LANTAS: 0\n",
      "ADA: 0\n",
      "VAKSINASI: 0\n",
      "INFLUENZA: 0\n",
      "KETUA: 1\n",
      "SATGAS: 1\n",
      "IKAT: 1\n",
      "DOKTER: 1\n",
      "IDI: 1\n",
      "PROF: 1\n",
      "ZUBAIRI: 1\n",
      "DJOERBAN: 1\n",
      "PASTI: 0\n",
      "KAIT: 1\n",
      "D-5816582: 0\n",
      "VAKSIN-COVID-19-BAKAL-RUTIN-SETIAP-TAHUN-TERGANTUNG-INI-PENJELASANNYA: 0\n",
      "MULAI: 2\n",
      "SUNTIK: 2\n",
      "MASIH: 2\n",
      "AMPUH: 2\n",
      "LAWAN: 3\n",
      "VARIAN: 5\n",
      "DELTA: 4\n",
      "CS: 2\n",
      "PAKAR: 1\n",
      "AKU: 1\n",
      "1: 7\n",
      "ALAMI: 1\n",
      "TURUN: 2\n",
      "EFEKTIVITAS: 3\n",
      "CORONA: 1\n",
      "INGAT: 1\n",
      "JENIS: 1\n",
      "IKUT: 1\n",
      "STRAIN: 1\n",
      "VIRUS: 1\n",
      "JAWAB: 1\n",
      "SINGGUNG: 1\n",
      "RISET: 2\n",
      "IA: 8\n",
      "SEBUT: 1\n",
      "DASAR: 1\n",
      "PFIZER: 1\n",
      "MODERNA: 1\n",
      "BUKTI: 1\n",
      "D-5816534: 1\n",
      "RI-MULAI-SUNTIKKAN-BOOSTER-DI-2022-MASIHKAH-AMPUH-LAWAN-VARIAN-DELTA-CS: 1\n",
      "ALERT: 0\n",
      "KASUS: 0\n",
      "DKI: 0\n",
      "DATA: 0\n",
      "BALITBANGKES: 0\n",
      "13: 0\n",
      "NOVEMBER: 0\n",
      "TAMBAH: 0\n",
      "JAWA: 1\n",
      "BARAT: 0\n",
      "165: 1\n",
      "90: 0\n",
      "SULAWESI: 0\n",
      "UTARA: 0\n",
      "86: 0\n",
      "DALAM: 0\n",
      "SEMENTARA: 0\n",
      "ALPHA: 0\n",
      "BETA: 0\n",
      "ASAL: 0\n",
      "TOTAL: 0\n",
      "327: 0\n",
      "D-5812940: 0\n",
      "ALERT-KASUS-VARIAN-DELTA-COVID-19-DI-DKI-MENINGKAT: 0\n",
      "AS: 7\n",
      "DADAK: 0\n",
      "NAIK: 0\n",
      "LAGI: 0\n",
      "USAI: 0\n",
      "SERANG: 0\n",
      "SEMPAT: 0\n",
      "REDA: 0\n",
      "AMERIKA: 0\n",
      "SERIKAT: 0\n",
      "PADAHAL: 0\n",
      "CATAT: 0\n",
      "STABIL: 0\n",
      "PASCA: 0\n",
      "MUSIM: 0\n",
      "PANAS: 0\n",
      "KEPALA: 0\n",
      "NASIHAT: 0\n",
      "MEDIS: 0\n",
      "GEDUNG: 0\n",
      "PUTIH: 0\n",
      "ANTHONY: 0\n",
      "FAUCI: 0\n",
      "SENIN: 0\n",
      "15: 0\n",
      "11: 0\n",
      "TAHU: 0\n",
      "NASIONAL: 0\n",
      "57: 0\n",
      "PERSEN: 0\n",
      "MINGGU: 0\n",
      "PUNCAK: 0\n",
      "GELOMBANG: 0\n",
      "PASIEN: 0\n",
      "AREA: 0\n",
      "TENGAH: 0\n",
      "TIMUR: 0\n",
      "LAUT: 0\n",
      "D-5813949: 0\n",
      "CORONA-DI-AS-MENDADAK-NAIK-LAGI-USAI-SERANGAN-DELTA-SEMPAT-MEREDA: 0\n",
      "Document 4 term frequencies:\n",
      "WILAYAH: 0\n",
      "KAMU: 0\n",
      "SUDAH: 0\n",
      "BEBAS: 0\n",
      "COVID: 2\n",
      "-: 12\n",
      "19: 2\n",
      "CEK: 0\n",
      "34: 0\n",
      "KAB: 0\n",
      "KOTA: 0\n",
      "ZONA: 0\n",
      "HIJAU: 0\n",
      "BARU: 1\n",
      "JAKARTA: 4\n",
      "PERINTAH: 0\n",
      "RENCANA: 0\n",
      "TERAP: 0\n",
      "LAKU: 0\n",
      "BATAS: 0\n",
      "GIAT: 0\n",
      "MASYARAKAT: 0\n",
      "PPKM: 0\n",
      "LEVEL: 0\n",
      "3: 2\n",
      "HITUNG: 0\n",
      "24: 0\n",
      "DESEMBER: 0\n",
      "2021: 0\n",
      "2: 2\n",
      "JANUARI: 0\n",
      "NAMUN: 0\n",
      "MENTERI: 0\n",
      "SEHAT: 0\n",
      "RI: 9\n",
      "BIJAK: 0\n",
      "TAHAP: 0\n",
      "KAJI: 0\n",
      "TURUT: 0\n",
      "DIREKTUR: 0\n",
      "CEGAH: 0\n",
      "KENDALI: 0\n",
      "SAKIT: 0\n",
      "TULAR: 0\n",
      "LANGSUNG: 0\n",
      "P2PML: 0\n",
      "KEMENKES: 1\n",
      "DR: 0\n",
      "SITI: 0\n",
      "NADIA: 0\n",
      "TARMIZI: 0\n",
      "SIGNIFIKAN: 1\n",
      "HAL: 0\n",
      "PICU: 0\n",
      "TINGKAT: 2\n",
      "MOBILITAS: 0\n",
      "LONGGAR: 0\n",
      "PROTOKOL: 0\n",
      "HTTPS: 1\n",
      "HEALTH: 2\n",
      "DETIK: 2\n",
      "COM: 1\n",
      "BERITA-DETIKHEALTH: 1\n",
      "D-5816690: 0\n",
      "WILAYAH-KAMU-SUDAH-BEBAS-COVID-19-CEK-34-KABKOTA-ZONA-HIJAU-TERBARU: 0\n",
      "VAKSIN: 0\n",
      "BAKAL: 0\n",
      "RUTIN: 0\n",
      "TIAP: 0\n",
      "TAHUN: 0\n",
      "GANTUNG: 0\n",
      "INI: 0\n",
      "JELAS: 0\n",
      "BERI: 1\n",
      "BOOSTER: 0\n",
      "DOSIS: 0\n",
      "TIGA: 0\n",
      "INDONESIA: 1\n",
      "2022: 0\n",
      "LANTAS: 0\n",
      "ADA: 0\n",
      "VAKSINASI: 0\n",
      "INFLUENZA: 0\n",
      "KETUA: 0\n",
      "SATGAS: 0\n",
      "IKAT: 0\n",
      "DOKTER: 0\n",
      "IDI: 0\n",
      "PROF: 0\n",
      "ZUBAIRI: 0\n",
      "DJOERBAN: 0\n",
      "PASTI: 0\n",
      "KAIT: 0\n",
      "D-5816582: 0\n",
      "VAKSIN-COVID-19-BAKAL-RUTIN-SETIAP-TAHUN-TERGANTUNG-INI-PENJELASANNYA: 0\n",
      "MULAI: 0\n",
      "SUNTIK: 0\n",
      "MASIH: 0\n",
      "AMPUH: 0\n",
      "LAWAN: 0\n",
      "VARIAN: 7\n",
      "DELTA: 5\n",
      "CS: 0\n",
      "PAKAR: 0\n",
      "AKU: 0\n",
      "1: 6\n",
      "ALAMI: 1\n",
      "TURUN: 0\n",
      "EFEKTIVITAS: 0\n",
      "CORONA: 0\n",
      "INGAT: 0\n",
      "JENIS: 0\n",
      "IKUT: 0\n",
      "STRAIN: 0\n",
      "VIRUS: 0\n",
      "JAWAB: 0\n",
      "SINGGUNG: 0\n",
      "RISET: 0\n",
      "IA: 8\n",
      "SEBUT: 0\n",
      "DASAR: 0\n",
      "PFIZER: 0\n",
      "MODERNA: 0\n",
      "BUKTI: 0\n",
      "D-5816534: 0\n",
      "RI-MULAI-SUNTIKKAN-BOOSTER-DI-2022-MASIHKAH-AMPUH-LAWAN-VARIAN-DELTA-CS: 0\n",
      "ALERT: 2\n",
      "KASUS: 2\n",
      "DKI: 5\n",
      "DATA: 1\n",
      "BALITBANGKES: 2\n",
      "13: 1\n",
      "NOVEMBER: 1\n",
      "TAMBAH: 2\n",
      "JAWA: 1\n",
      "BARAT: 1\n",
      "165: 1\n",
      "90: 1\n",
      "SULAWESI: 1\n",
      "UTARA: 1\n",
      "86: 1\n",
      "DALAM: 1\n",
      "SEMENTARA: 1\n",
      "ALPHA: 1\n",
      "BETA: 1\n",
      "ASAL: 1\n",
      "TOTAL: 1\n",
      "327: 1\n",
      "D-5812940: 1\n",
      "ALERT-KASUS-VARIAN-DELTA-COVID-19-DI-DKI-MENINGKAT: 1\n",
      "AS: 3\n",
      "DADAK: 0\n",
      "NAIK: 0\n",
      "LAGI: 0\n",
      "USAI: 0\n",
      "SERANG: 0\n",
      "SEMPAT: 0\n",
      "REDA: 0\n",
      "AMERIKA: 0\n",
      "SERIKAT: 0\n",
      "PADAHAL: 0\n",
      "CATAT: 0\n",
      "STABIL: 0\n",
      "PASCA: 0\n",
      "MUSIM: 0\n",
      "PANAS: 0\n",
      "KEPALA: 0\n",
      "NASIHAT: 0\n",
      "MEDIS: 0\n",
      "GEDUNG: 0\n",
      "PUTIH: 0\n",
      "ANTHONY: 0\n",
      "FAUCI: 0\n",
      "SENIN: 0\n",
      "15: 0\n",
      "11: 0\n",
      "TAHU: 0\n",
      "NASIONAL: 0\n",
      "57: 0\n",
      "PERSEN: 0\n",
      "MINGGU: 0\n",
      "PUNCAK: 0\n",
      "GELOMBANG: 0\n",
      "PASIEN: 0\n",
      "AREA: 0\n",
      "TENGAH: 0\n",
      "TIMUR: 0\n",
      "LAUT: 0\n",
      "D-5813949: 0\n",
      "CORONA-DI-AS-MENDADAK-NAIK-LAGI-USAI-SERANGAN-DELTA-SEMPAT-MEREDA: 0\n",
      "Document 5 term frequencies:\n",
      "WILAYAH: 1\n",
      "KAMU: 0\n",
      "SUDAH: 0\n",
      "BEBAS: 0\n",
      "COVID: 3\n",
      "-: 16\n",
      "19: 3\n",
      "CEK: 0\n",
      "34: 0\n",
      "KAB: 0\n",
      "KOTA: 0\n",
      "ZONA: 0\n",
      "HIJAU: 0\n",
      "BARU: 0\n",
      "JAKARTA: 1\n",
      "PERINTAH: 0\n",
      "RENCANA: 0\n",
      "TERAP: 0\n",
      "LAKU: 0\n",
      "BATAS: 0\n",
      "GIAT: 0\n",
      "MASYARAKAT: 0\n",
      "PPKM: 0\n",
      "LEVEL: 0\n",
      "3: 1\n",
      "HITUNG: 0\n",
      "24: 0\n",
      "DESEMBER: 0\n",
      "2021: 1\n",
      "2: 2\n",
      "JANUARI: 0\n",
      "NAMUN: 1\n",
      "MENTERI: 0\n",
      "SEHAT: 0\n",
      "RI: 5\n",
      "BIJAK: 0\n",
      "TAHAP: 0\n",
      "KAJI: 0\n",
      "TURUT: 0\n",
      "DIREKTUR: 0\n",
      "CEGAH: 0\n",
      "KENDALI: 0\n",
      "SAKIT: 0\n",
      "TULAR: 0\n",
      "LANGSUNG: 0\n",
      "P2PML: 0\n",
      "KEMENKES: 0\n",
      "DR: 1\n",
      "SITI: 0\n",
      "NADIA: 0\n",
      "TARMIZI: 0\n",
      "SIGNIFIKAN: 0\n",
      "HAL: 2\n",
      "PICU: 0\n",
      "TINGKAT: 0\n",
      "MOBILITAS: 0\n",
      "LONGGAR: 0\n",
      "PROTOKOL: 0\n",
      "HTTPS: 1\n",
      "HEALTH: 2\n",
      "DETIK: 2\n",
      "COM: 1\n",
      "BERITA-DETIKHEALTH: 1\n",
      "D-5816690: 0\n",
      "WILAYAH-KAMU-SUDAH-BEBAS-COVID-19-CEK-34-KABKOTA-ZONA-HIJAU-TERBARU: 0\n",
      "VAKSIN: 0\n",
      "BAKAL: 0\n",
      "RUTIN: 0\n",
      "TIAP: 0\n",
      "TAHUN: 0\n",
      "GANTUNG: 0\n",
      "INI: 0\n",
      "JELAS: 0\n",
      "BERI: 1\n",
      "BOOSTER: 0\n",
      "DOSIS: 0\n",
      "TIGA: 0\n",
      "INDONESIA: 0\n",
      "2022: 0\n",
      "LANTAS: 0\n",
      "ADA: 5\n",
      "VAKSINASI: 0\n",
      "INFLUENZA: 0\n",
      "KETUA: 0\n",
      "SATGAS: 0\n",
      "IKAT: 1\n",
      "DOKTER: 0\n",
      "IDI: 0\n",
      "PROF: 0\n",
      "ZUBAIRI: 0\n",
      "DJOERBAN: 0\n",
      "PASTI: 0\n",
      "KAIT: 0\n",
      "D-5816582: 0\n",
      "VAKSIN-COVID-19-BAKAL-RUTIN-SETIAP-TAHUN-TERGANTUNG-INI-PENJELASANNYA: 0\n",
      "MULAI: 0\n",
      "SUNTIK: 0\n",
      "MASIH: 0\n",
      "AMPUH: 0\n",
      "LAWAN: 0\n",
      "VARIAN: 2\n",
      "DELTA: 4\n",
      "CS: 0\n",
      "PAKAR: 0\n",
      "AKU: 0\n",
      "1: 8\n",
      "ALAMI: 0\n",
      "TURUN: 1\n",
      "EFEKTIVITAS: 0\n",
      "CORONA: 2\n",
      "INGAT: 0\n",
      "JENIS: 0\n",
      "IKUT: 0\n",
      "STRAIN: 0\n",
      "VIRUS: 0\n",
      "JAWAB: 0\n",
      "SINGGUNG: 0\n",
      "RISET: 0\n",
      "IA: 2\n",
      "SEBUT: 0\n",
      "DASAR: 0\n",
      "PFIZER: 0\n",
      "MODERNA: 0\n",
      "BUKTI: 0\n",
      "D-5816534: 0\n",
      "RI-MULAI-SUNTIKKAN-BOOSTER-DI-2022-MASIHKAH-AMPUH-LAWAN-VARIAN-DELTA-CS: 0\n",
      "ALERT: 0\n",
      "KASUS: 1\n",
      "DKI: 0\n",
      "DATA: 0\n",
      "BALITBANGKES: 0\n",
      "13: 1\n",
      "NOVEMBER: 0\n",
      "TAMBAH: 0\n",
      "JAWA: 0\n",
      "BARAT: 1\n",
      "165: 0\n",
      "90: 0\n",
      "SULAWESI: 0\n",
      "UTARA: 0\n",
      "86: 0\n",
      "DALAM: 0\n",
      "SEMENTARA: 0\n",
      "ALPHA: 0\n",
      "BETA: 0\n",
      "ASAL: 0\n",
      "TOTAL: 0\n",
      "327: 0\n",
      "D-5812940: 0\n",
      "ALERT-KASUS-VARIAN-DELTA-COVID-19-DI-DKI-MENINGKAT: 0\n",
      "AS: 10\n",
      "DADAK: 3\n",
      "NAIK: 2\n",
      "LAGI: 2\n",
      "USAI: 2\n",
      "SERANG: 3\n",
      "SEMPAT: 2\n",
      "REDA: 2\n",
      "AMERIKA: 1\n",
      "SERIKAT: 1\n",
      "PADAHAL: 1\n",
      "CATAT: 1\n",
      "STABIL: 1\n",
      "PASCA: 1\n",
      "MUSIM: 2\n",
      "PANAS: 2\n",
      "KEPALA: 1\n",
      "NASIHAT: 1\n",
      "MEDIS: 1\n",
      "GEDUNG: 1\n",
      "PUTIH: 1\n",
      "ANTHONY: 1\n",
      "FAUCI: 1\n",
      "SENIN: 1\n",
      "15: 1\n",
      "11: 1\n",
      "TAHU: 1\n",
      "NASIONAL: 1\n",
      "57: 1\n",
      "PERSEN: 1\n",
      "MINGGU: 1\n",
      "PUNCAK: 1\n",
      "GELOMBANG: 1\n",
      "PASIEN: 1\n",
      "AREA: 1\n",
      "TENGAH: 1\n",
      "TIMUR: 1\n",
      "LAUT: 1\n",
      "D-5813949: 1\n",
      "CORONA-DI-AS-MENDADAK-NAIK-LAGI-USAI-SERANGAN-DELTA-SEMPAT-MEREDA: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "from spacy.lang.id.stop_words import STOP_WORDS\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from collections import defaultdict\n",
    "\n",
    "def termFrequencyInDoc(vocab, doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_docs[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id,doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    return tf_docs\n",
    "\n",
    "preprocessed_docs = {}\n",
    "\n",
    "# Inisialisasi model bahasa Spacy untuk Bahasa Indonesia\n",
    "nlp = spacy.blank(\"id\")\n",
    "\n",
    "# Inisialisasi Stemmer dari Sastrawi\n",
    "stemmer_factory = StemmerFactory()\n",
    "stemmer = stemmer_factory.create_stemmer()\n",
    "\n",
    "path = \"C:/Users/Afi/Downloads/berita~/berita\"\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    # Tokenisasi dengan Spacy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    # Eliminasi stopword\n",
    "    tokens = [token for token in tokens if token not in STOP_WORDS]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def preprocess_text(text, stem=True, lowercase=False):\n",
    "    # Tokenisasi dan eliminasi stopword\n",
    "    tokens = tokenize_and_remove_stopwords(text)\n",
    "    \n",
    "    # Stemming jika diperlukan\n",
    "    if stem:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Case folding\n",
    "    if lowercase:\n",
    "        text = ' '.join(tokens).lower()\n",
    "    else:\n",
    "        text = ' '.join(tokens).upper()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Inisialisasi inverted index\n",
    "inverted_index = {}\n",
    "\n",
    "# Loop untuk membaca dan memproses setiap dokumen\n",
    "for i, file in enumerate(os.listdir(path)):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(path, file)\n",
    "        content = read_text_file(file_path)\n",
    "        preprocessed_text = preprocess_text(content)\n",
    "        preprocessed_docs[i + 1] = preprocessed_text\n",
    "        \n",
    "        # Tokenisasi teks yang telah diproses\n",
    "        tokens = preprocessed_text.split()\n",
    "        \n",
    "        # Membuat inverted index\n",
    "        for term in tokens:\n",
    "            if term not in inverted_index:\n",
    "                inverted_index[term] = []\n",
    "            if (term in inverted_index) and ((i+1) not in inverted_index[term]):\n",
    "                inverted_index[term].append(i+1)\n",
    "                \n",
    "\n",
    "\n",
    "vocab=list(inverted_index.keys())\n",
    "tf_docs = termFrequencyInDoc(vocab, preprocessed_docs)\n",
    "\n",
    "for doc_id, tf in tf_docs.items():\n",
    "    print(f\"Document {doc_id} term frequencies:\")\n",
    "    for term, frequency in tf.items():\n",
    "        print(f\"{term}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f711cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.38629436  0.          0.          0.          1.69314718]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 3.          7.          4.          2.          3.        ]\n",
      " [16.         18.         20.         12.         16.        ]\n",
      " [ 3.          7.          4.          2.          3.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          2.09861229  0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 2.81093022  0.          1.40546511  1.40546511  0.        ]\n",
      " [ 1.          1.          1.          4.          1.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 1.69314718  1.69314718  0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 6.29583687  0.          0.          0.          0.        ]\n",
      " [ 6.29583687  0.          0.          0.          0.        ]\n",
      " [10.49306144  0.          2.09861229  4.19722458  2.09861229]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 3.38629436  0.          0.          0.          1.69314718]\n",
      " [11.85203026  6.77258872 18.62461899  3.38629436  3.38629436]\n",
      " [ 1.69314718  1.69314718  0.          0.          0.        ]\n",
      " [ 1.69314718  0.          0.          0.          1.69314718]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 4.19722458  0.          0.          0.          0.        ]\n",
      " [ 8.43279065  5.62186043 15.46011619 12.64918597  7.02732554]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 1.69314718  1.69314718  0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 1.69314718  0.          0.          1.69314718  0.        ]\n",
      " [ 1.69314718  0.          0.          0.          1.69314718]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 1.69314718  0.          0.          1.69314718  0.        ]\n",
      " [ 1.69314718  0.          0.          0.          3.38629436]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 1.69314718  0.          0.          3.38629436  0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [ 2.          2.          2.          2.          2.        ]\n",
      " [ 2.          2.          2.          2.          2.        ]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 2.09861229  0.          0.          0.          0.        ]\n",
      " [ 0.         11.85203026 10.15888308  0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 0.          4.19722458  0.          0.          0.        ]\n",
      " [ 2.09861229  4.19722458  2.09861229  2.09861229  2.09861229]\n",
      " [ 0.          3.38629436  5.07944154  0.          0.        ]\n",
      " [ 0.          1.69314718  5.07944154  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          2.81093022  2.81093022  1.40546511  0.        ]\n",
      " [ 0.          1.69314718  5.07944154  0.          0.        ]\n",
      " [ 0.          2.09861229  0.          0.          0.        ]\n",
      " [ 0.          1.69314718  0.          0.          8.4657359 ]\n",
      " [ 0.          6.29583687  0.          0.          0.        ]\n",
      " [ 0.          2.09861229  0.          0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          1.69314718]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          2.09861229  0.          0.          0.        ]\n",
      " [ 0.          1.69314718  1.69314718  0.          0.        ]\n",
      " [ 0.          2.09861229  0.          0.          0.        ]\n",
      " [ 0.          2.09861229  0.          0.          0.        ]\n",
      " [ 0.          0.          4.19722458  0.          0.        ]\n",
      " [ 0.          0.          4.19722458  0.          0.        ]\n",
      " [ 0.          0.          4.19722458  0.          0.        ]\n",
      " [ 0.          0.          4.19722458  0.          0.        ]\n",
      " [ 0.          0.          6.29583687  0.          0.        ]\n",
      " [ 0.          0.          7.02732554  9.83825576  2.81093022]\n",
      " [ 0.          0.          5.62186043  7.02732554  5.62186043]\n",
      " [ 0.          0.          4.19722458  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 2.09861229  0.          2.09861229  0.          0.        ]\n",
      " [10.15888308 13.54517744 11.85203026 10.15888308 13.54517744]\n",
      " [ 0.          0.          1.69314718  1.69314718  0.        ]\n",
      " [ 0.          0.          3.38629436  0.          1.69314718]\n",
      " [ 0.          0.          6.29583687  0.          0.        ]\n",
      " [ 0.          0.          1.69314718  0.          3.38629436]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          4.19722458  0.          0.        ]\n",
      " [ 4.19722458  8.39444915 16.78889831 16.78889831  4.19722458]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          2.09861229  0.          0.        ]\n",
      " [ 0.          0.          0.          4.19722458  0.        ]\n",
      " [ 0.          0.          0.          3.38629436  1.69314718]\n",
      " [ 0.          0.          0.         10.49306144  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          4.19722458  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  2.09861229]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          4.19722458  0.        ]\n",
      " [ 0.          0.          2.09861229  2.09861229  0.        ]\n",
      " [ 0.          0.          0.          1.69314718  1.69314718]\n",
      " [ 0.          2.09861229  2.09861229  2.09861229  0.        ]\n",
      " [ 2.09861229  0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [ 0.          0.          0.          2.09861229  0.        ]\n",
      " [10.49306144 16.78889831 14.69028602  6.29583687 20.98612289]\n",
      " [ 0.          0.          0.          0.          6.29583687]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          6.29583687]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          4.19722458]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          4.19722458  0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]\n",
      " [ 0.          0.          0.          0.          2.09861229]]\n"
     ]
    }
   ],
   "source": [
    "#NO 1\n",
    "def wordDocFre(vocab, doc_dict):\n",
    "    df = {}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenisasi(doc):\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "    return df\n",
    "\n",
    "def tokenisasi(text):\n",
    "    # Memisahkan teks menjadi kata-kata berdasarkan spasi\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "import numpy as np\n",
    "def inverseDocFre(vocab,doc_fre,length):\n",
    "    idf= {}\n",
    "    for word in vocab:\n",
    "        idf[word] = idf[word] = 1 + np.log((length + 1) / (doc_fre[word]+1))\n",
    "    return idf\n",
    "\n",
    "def tfidf(vocab,tf,idf_scr,doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id,doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    return tf_idf_scr\n",
    "\n",
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab, preprocessed_docs), inverseDocFre(vocab, wordDocFre(vocab, preprocessed_docs), len(preprocessed_docs)), preprocessed_docs)\n",
    "\n",
    "# Term - Document Matrix\n",
    "TD = np.zeros((len(vocab), len(preprocessed_docs)))\n",
    "for word in vocab:\n",
    "    for doc_id,doc in tf_idf.items():\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "print(TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e979482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Afi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bandingkan similarity matrix dengan:\n",
      "1. Edit Distance\n",
      "2. Jaccard Similarity\n",
      "3. Euclidean Distance\n",
      "4. Cosine Similarity\n",
      "5. Keluar dari program\n",
      "Nomor menu yang ingin anda lakukan: 1\n",
      "Similarity Matrix using Edit Distance:\n",
      "[[  0. 541. 616. 483. 523.]\n",
      " [541.   0. 554. 519. 525.]\n",
      " [616. 554.   0. 606. 604.]\n",
      " [483. 519. 606.   0. 486.]\n",
      " [523. 525. 604. 486.   0.]]\n",
      "\n",
      "Bandingkan similarity matrix dengan:\n",
      "1. Edit Distance\n",
      "2. Jaccard Similarity\n",
      "3. Euclidean Distance\n",
      "4. Cosine Similarity\n",
      "5. Keluar dari program\n",
      "Nomor menu yang ingin anda lakukan: 2\n",
      "Similarity Matrix using Jaccard Similarity:\n",
      "[[0.         0.10447761 0.10666667 0.1171875  0.11267606]\n",
      " [0.10447761 0.         0.248      0.10833333 0.0962963 ]\n",
      " [0.10666667 0.248      0.         0.15267176 0.12162162]\n",
      " [0.1171875  0.10833333 0.15267176 0.         0.13492063]\n",
      " [0.11267606 0.0962963  0.12162162 0.13492063 0.        ]]\n",
      "\n",
      "Bandingkan similarity matrix dengan:\n",
      "1. Edit Distance\n",
      "2. Jaccard Similarity\n",
      "3. Euclidean Distance\n",
      "4. Cosine Similarity\n",
      "5. Keluar dari program\n",
      "Nomor menu yang ingin anda lakukan: 5\n",
      "Keluar dari program.\n"
     ]
    }
   ],
   "source": [
    "#NO 2\n",
    "def edit_distance(string1, string2):\n",
    "    if len(string1) > len(string2):\n",
    "        difference = len(string1) - len(string2)\n",
    "        string1[:difference]\n",
    "        n = len(string2)\n",
    "    elif len(string2) > len(string1):\n",
    "        difference = len(string2) - len(string1)\n",
    "        string2[:difference]\n",
    "        n = len(string1)\n",
    "    for i in range(n):\n",
    "        if string1[i] != string2[i]:\n",
    "            difference += 1\n",
    "    return difference\n",
    "\n",
    "def jaccard_sim(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "def euclidian_dist(vec1, vec2):\n",
    "    # subtracting vector\n",
    "    temp = vec1 - vec2\n",
    "    # doing dot product\n",
    "    # for finding\n",
    "    # sum of the squares\n",
    "    sum_sq = np.dot(temp.T, temp)\n",
    "    # Doing squareroot and\n",
    "    # printing Euclidean distance\n",
    "    return np.sqrt(sum_sq)\n",
    "\n",
    "import math\n",
    "def cosine_sim(vec1, vec2):\n",
    "    vec1 = list(vec1)\n",
    "    vec2 = list(vec2)\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return dot_prod / (mag_1 * mag_2)\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "from nltk.metrics import edit_distance\n",
    "from scipy.spatial.distance import jaccard, euclidean\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "\n",
    "def preprocess_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    tokens = nltk.word_tokenize(content)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def calculate_similarity_matrix(documents, similarity_metric):\n",
    "    if similarity_metric == 'Edit Distance':\n",
    "        similarity_matrix = np.zeros((len(documents), len(documents)))\n",
    "        for i in range(len(documents)):\n",
    "            for j in range(i + 1, len(documents)):\n",
    "                similarity_matrix[i][j] = edit_distance(documents[i], documents[j])\n",
    "                similarity_matrix[j][i] = similarity_matrix[i][j]\n",
    "    elif similarity_metric == 'Jaccard Similarity':\n",
    "        similarity_matrix = np.zeros((len(documents), len(documents)))\n",
    "        for i in range(len(documents)):\n",
    "            for j in range(i + 1, len(documents)):\n",
    "                set1 = set(documents[i].split())\n",
    "                set2 = set(documents[j].split())\n",
    "                intersection = len(set1.intersection(set2))\n",
    "                union = len(set1.union(set2))\n",
    "                similarity_matrix[i][j] = intersection / union\n",
    "                similarity_matrix[j][i] = similarity_matrix[i][j]\n",
    "    elif similarity_metric == 'Euclidean Distance':\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "        similarity_matrix = np.zeros((len(documents), len(documents)))\n",
    "        for i in range(len(documents)):\n",
    "            for j in range(i + 1, len(documents)):\n",
    "                similarity_matrix[i][j] = euclidean(tfidf_matrix[i].toarray(), tfidf_matrix[j].toarray())\n",
    "                similarity_matrix[j][i] = similarity_matrix[i][j]\n",
    "    elif similarity_metric == 'Cosine Similarity':\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "        similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    else:\n",
    "        similarity_matrix = None\n",
    "    return similarity_matrix\n",
    "\n",
    "folder_path = \"C:/Users/Afi/Downloads/berita~/berita\"\n",
    "file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]\n",
    "\n",
    "documents = [preprocess_text(file_path) for file_path in file_paths]\n",
    "\n",
    "while True:\n",
    "    print(\"\\nBandingkan similarity matrix dengan:\")\n",
    "    print(\"1. Edit Distance\")\n",
    "    print(\"2. Jaccard Similarity\")\n",
    "    print(\"3. Euclidean Distance\")\n",
    "    print(\"4. Cosine Similarity\")\n",
    "    print(\"5. Keluar dari program\")\n",
    "    \n",
    "    choice = input(\"Nomor menu yang ingin anda lakukan: \")\n",
    "    \n",
    "    if choice == '1':\n",
    "        similarity_metric = 'Edit Distance'\n",
    "    elif choice == '2':\n",
    "        similarity_metric = 'Jaccard Similarity'\n",
    "    elif choice == '3':\n",
    "        similarity_metric = 'Euclidean Distance'\n",
    "    elif choice == '4':\n",
    "        similarity_metric = 'Cosine Similarity'\n",
    "    elif choice == '5':\n",
    "        print(\"Keluar dari program.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Pilihan tidak valid. Silakan masukkan nomor yang sesuai.\")\n",
    "        continue\n",
    "    \n",
    "    similarity_matrix = calculate_similarity_matrix(documents, similarity_metric)\n",
    "    \n",
    "    if similarity_matrix is not None:\n",
    "        print(f\"Similarity Matrix using {similarity_metric}:\")\n",
    "        print(similarity_matrix)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea5a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
